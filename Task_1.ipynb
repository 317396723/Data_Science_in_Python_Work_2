{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee52f615",
   "metadata": {},
   "source": [
    "# COMP41680 Assignment 2 - Part_1\n",
    "Name: Shuhao Guan  \n",
    "ID: 20211120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6161",
   "metadata": {},
   "source": [
    "## Task 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14e670",
   "metadata": {},
   "source": [
    "**1. Scrape the complete set of web pages from your personal website address:**\n",
    "- http://mlg.ucd.ie/modules/python/assign2/20211120/ \n",
    "\n",
    "**2. From the web pages above, parse every review across all years 2016-2021. For each product review, extract the following information:** \n",
    "\n",
    "- The star rating of the review \n",
    "- The title text of the review \n",
    "- The main body text of the review \n",
    "- Review helpfulness information \n",
    "\n",
    "**3. Store the parsed review data in an appropriate format.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6270fc",
   "metadata": {},
   "source": [
    "### Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72db14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d05d2a",
   "metadata": {},
   "source": [
    "### Scrape all page names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b1f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_ = \"http://mlg.ucd.ie/modules/python/assign2/20211120/\"\n",
    "response_ = urllib.request.urlopen(link_)\n",
    "html_ = response_.read().decode()\n",
    "parser_ = bs4.BeautifulSoup(html_,\"html.parser\")\n",
    "# start=int(parser2.find_all(\"div\", class_=\"jumbotron\")[0].p.get_text().split(\" \")[5])\n",
    "# end=int(parser2.find_all(\"div\", class_=\"jumbotron\")[0].p.get_text().split(\" \")[7][:-1])\n",
    "list=[]\n",
    "for i in parser_.find_all(\"div\", class_=\"list-group\"):\n",
    "    for j in i.find_all('a'):\n",
    "        for k in range((int(str(j).split(\"[\")[1][:-5])-1)//30+1):\n",
    "#             print(str(j).split(\"[\")[1][:-5])\n",
    "            list.append(str(j).split(\"\\\"\")[3][:-7]+str(k+1).zfill(2)+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3743e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reviews-2016-jan-01.html',\n",
       " 'reviews-2016-jan-02.html',\n",
       " 'reviews-2016-jan-03.html',\n",
       " 'reviews-2016-jan-04.html',\n",
       " 'reviews-2016-jan-05.html']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4252ed",
   "metadata": {},
   "source": [
    "### Scrape all review information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2673fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def got(links):\n",
    "    dfall=pd.DataFrame()\n",
    "    for link in links:\n",
    "#         print(link)\n",
    "        response = urllib.request.urlopen(\"http://mlg.ucd.ie/modules/python/assign2/20211120/\"+link)\n",
    "        html = response.read().decode()\n",
    "        parser = bs4.BeautifulSoup(html,\"html.parser\")\n",
    "        # star\n",
    "        star=[]\n",
    "        stars = parser.find_all('img')\n",
    "        for i in stars:\n",
    "            star.append(int(i[\"alt\"].split('-')[0]))\n",
    "        # title\n",
    "        title=[]\n",
    "        titles = parser.find_all('h5')\n",
    "        for i in titles:\n",
    "            title.append(i.get_text().split('\\xa0')[1])\n",
    "        #helpful\n",
    "        helpful1=[]\n",
    "        helpful2=[]\n",
    "        for i in range(1,len(parser.find_all(\"p\", class_=\"metadata\")),2):\n",
    "        #     print(parser.find_all(\"p\", class_=\"metadata\")[i].get_text())\n",
    "            helpful1.append(int(parser.find_all(\"p\", class_=\"metadata\")[i].get_text().split(\" \")[0]))\n",
    "            helpful2.append(int(parser.find_all(\"p\", class_=\"metadata\")[i].get_text().split(\" \")[3]))\n",
    "        # review\n",
    "        review=[]\n",
    "        reviews=parser.find_all(\"p\", class_=\"review-body\")\n",
    "        for i in reviews:\n",
    "            review.append(i.get_text())\n",
    "        # parser.find_all(\"p\", class_=\"review-body\")[0].get_text()\n",
    "        df=[star,title,review,helpful1,helpful2]\n",
    "        df=pd.DataFrame(df)\n",
    "        df=df.T\n",
    "        # Python program to demonstrate\n",
    "        # writing to CSV\n",
    "        dfall=pd.concat([dfall, df])\n",
    "\n",
    "        # field names\n",
    "        fields = ['star','title','review','helpful1','helpful2']\n",
    "        # name of csv file\n",
    "        if not os.path.exists(\"./data\"):\n",
    "            os.makedirs(\"./data\")\n",
    "        filename = \"./data/\"+link.split(\".\")[0]+\".csv\"\n",
    "        # writing to csv file\n",
    "        with open(filename, 'w',encoding='utf-8') as csvfile:\n",
    "            # creating a csv writer object\n",
    "            csvwriter = csv.writer(csvfile, lineterminator='\\n')\n",
    "            # writing the fields\n",
    "            csvwriter.writerow(fields)\n",
    "            # writing the data rows\n",
    "            csvwriter.writerows(df.values)\n",
    "    dfall.columns=['star','title','review','helpful1','helpful2']\n",
    "    if not os.path.exists(\"./merged_data\"):\n",
    "        os.makedirs(\"./merged_data\")\n",
    "    dfall.to_csv(\"./merged_data/review.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d095b36",
   "metadata": {},
   "source": [
    "I have stored the separate data and the merged data separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500cc32",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb25bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "got(list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
